{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8e7d56e",
   "metadata": {},
   "source": [
    "This notebook contains the processing code for the Mackay Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86baf622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import missingno as msno\n",
    "\n",
    "from bokeh.io import output_file, show , output_notebook\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource,  LabelSet\n",
    "from bokeh.palettes import Viridis256,all_palettes,BrBG, PiYG, RdGy, RdYlGn, YlGnBu, PuBuGn, Colorblind, Bokeh,Category20,Accent\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sn\n",
    "from random import randrange\n",
    "from lifelines import CoxPHFitter,KaplanMeierFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "valuable-catholic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total video files of different Patients in a4c of is  13152\n",
      "Total unique Patients in 20200827_pEF_ECHO.csv is 4127\n",
      "Total unique Patients in 20200827_rEF_ECHO.csv is 3705\n",
      "Total unique Patients in Extracted_PIDs_cleaned.csv  7492 \n",
      "\n",
      "common Patients in pef_PID and Extra_PID is  367\n",
      "common Patients in pef_PID and ref_PID is  250\n",
      "common Patients in Extra_PID and ref_PID is  111 \n",
      "\n",
      "total Patients in all of them is  14615 \n",
      "\n",
      "common Patients in all the csv files and video files is 12173\n"
     ]
    }
   ],
   "source": [
    "#checking the data files and common PID in the files\n",
    "root = \"data\"\n",
    "data = \"A4C\"\n",
    "extension = \".mp4\"\n",
    "a4c = os.listdir(os.path.join(root,data))\n",
    "pef = pd.read_csv('20200827_pEF_ECHO.csv')\n",
    "pef['PatientID'] = pef['PatientID'].astype(str)\n",
    "ref = pd.read_csv('20200827_rEF_ECHO.csv')\n",
    "ref['PatientID'] = ref['PatientID'].astype(str)\n",
    "Extracted_PID = pd.read_csv('Extracted_PIDs_cleaned.csv')\n",
    "Extracted_PID['PatientID'] = Extracted_PID['PatientID'].astype(str)\n",
    "\n",
    "print(\"Total video files of different Patients in a4c of is \", len(a4c))\n",
    "print(\"Total unique Patients in 20200827_pEF_ECHO.csv is\" , len(pef['PatientID'].unique()))\n",
    "print(\"Total unique Patients in 20200827_rEF_ECHO.csv is\" , len(ref['PatientID'].unique()))\n",
    "print(\"Total unique Patients in Extracted_PIDs_cleaned.csv \" , len(Extracted_PID['PatientID'].unique()),\"\\n\")\n",
    "\n",
    "pef_PID = set(pef['PatientID'].unique())\n",
    "ref_PID = set(ref['PatientID'].unique())\n",
    "Extra_PID = set(Extracted_PID['PatientID'].unique())\n",
    "Total_csv_PID = pef_PID.union(ref_PID).union(Extra_PID)\n",
    "Total_video_PID = set(a4c)\n",
    "\n",
    "print(\"common Patients in pef_PID and Extra_PID is \", len(pef_PID.intersection(Extra_PID)))\n",
    "print(\"common Patients in pef_PID and ref_PID is \", len(pef_PID.intersection(ref_PID)))\n",
    "print(\"common Patients in Extra_PID and ref_PID is \", len(Extra_PID.intersection(ref_PID)), \"\\n\")\n",
    "print(\"total Patients in all of them is \" , len(Total_csv_PID),\"\\n\")\n",
    "\n",
    "print(\"common Patients in all the csv files and video files is\",len(Total_video_PID.intersection(Total_csv_PID)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "suffering-albania",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_dataset(MasterData):\n",
    "    baseline = MasterData.loc[MasterData['Event_Name']=='Baseline'].reset_index(drop=True)\n",
    "    baseline = baseline.sort_values(by=['PatientID']).reset_index(drop=True)\n",
    "    after_event = MasterData.loc[MasterData['Event_Name']=='EventDay'].reset_index(drop=True)\n",
    "    after_event = after_event.sort_values(by=['PatientID']).reset_index(drop=True)\n",
    "    \n",
    "    Dataframe = baseline.copy(deep=True)\n",
    "    Dataframe['LVEF_label'] = after_event['Ef'].values\n",
    "\n",
    "    gender = []\n",
    "    for i in range(len(Dataframe)):\n",
    "        if(Dataframe['gender'][i]=='Male' or Dataframe['gender'][i]==1):\n",
    "            gender.append(1)\n",
    "        else:\n",
    "            gender.append(0)\n",
    "            \n",
    "    Dataframe['gender'] = gender\n",
    "    Dataframe['change_in_LVEF'] = Dataframe['LVEF_label'] - Dataframe['Ef']\n",
    "    Dataframe['change_in_LVEF(in%)'] = ((Dataframe['LVEF_label'] - Dataframe['Ef'])/Dataframe['Ef'])*100\n",
    "    Dataframe['absolute_change_in_LVEF(in%)'] = abs(((Dataframe['LVEF_label'] - Dataframe['Ef'])/Dataframe['Ef'])*100)\n",
    "\n",
    "    class_label = []\n",
    "    for i in range(len(Dataframe)):\n",
    "        if(Dataframe['change_in_LVEF(in%)'][i]<-5):\n",
    "            class_label.append(1)\n",
    "        elif (Dataframe['change_in_LVEF(in%)'][i]>5):\n",
    "            class_label.append(2)\n",
    "        else:\n",
    "            class_label.append(0)\n",
    "\n",
    "    Dataframe['class'] = class_label\n",
    "\n",
    "    print(\"total class 0 is\" ,len(Dataframe.loc[Dataframe['class']==0]))\n",
    "    print(\"total class 1 is\" ,len(Dataframe.loc[Dataframe['class']==1]))\n",
    "    print(\"total class 2 is\" ,len(Dataframe.loc[Dataframe['class']==2]))\n",
    "\n",
    "    print(\"train set should contain\",len(Dataframe)*.8)\n",
    "    print(\"test set should contain\",len(Dataframe)*.20)\n",
    "    return Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-foster",
   "metadata": {},
   "source": [
    "# Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "administrative-mouth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows is  9745  and Total Patients is  7582\n",
      "Total Rows after null removal is  9657  and Total Patients is  7494\n"
     ]
    }
   ],
   "source": [
    "## Correcting the datetime of all the csv files\n",
    "ref['ExamDate'] = pd.to_datetime(ref['ExamDate'],dayfirst=True)\n",
    "pef['ExamDate'] = pd.to_datetime(pef['ExamDate'])\n",
    "Extracted_PID['ExamDate'] = pd.to_datetime(Extracted_PID['ExamDate'])\n",
    "\n",
    "## Working with the ref and pef data and dropping columns that have lots of null values\n",
    "ref = ref.drop(['folder'], axis = 1)\n",
    "pef = pef.drop(['folder'], axis = 1)\n",
    "\n",
    "masterData = pd.concat([ref,pef]).drop_duplicates().reset_index(drop=True)\n",
    "print(\"Total Rows is \", len(masterData), \" and Total Patients is \",len(masterData['PatientID'].unique()))\n",
    "masterData = masterData.sort_values(by=['PatientID','ExamDate']).reset_index(drop=True)\n",
    "\n",
    "masterData = masterData[masterData['ExamDate'].notna()]\n",
    "#masterData = masterData[masterData['Ef'].notna()]\n",
    "masterData = masterData.sort_values(by=['PatientID','ExamDate']).reset_index(drop=True)\n",
    "print(\"Total Rows after null removal is \", len(masterData), \" and Total Patients is \",len(masterData['PatientID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "supreme-split",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows before null removal is  18732  and Total Patients is  7492\n",
      "Total Rows after null removal is  18705  and Total Patients is  7490\n",
      "\n",
      "Total rows that have null in each columns is\n",
      " PatientID            0\n",
      "ExamDate             0\n",
      "Ivs               2904\n",
      "Lvpw              2910\n",
      "Lvidd             2907\n",
      "Lvids             2907\n",
      "Lvedv             4144\n",
      "Lvesv             4137\n",
      "Dt                3292\n",
      "Ivrt              3504\n",
      "E                 3170\n",
      "A                 3072\n",
      "TDI_e_lateral     8344\n",
      "TDI_e_septal     11621\n",
      "TDI_s_lateral    12097\n",
      "TDI_s_septal     12104\n",
      "LA_MAX_VOLUME    15435\n",
      "LA_MIN_VOLUME    15427\n",
      "TR_VELOCITY      14262\n",
      "Ef                4145\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#renmaing the columns to make it similar to Alberta\n",
    "Extracted_PID = Extracted_PID.drop(['Unnamed: 0', 'folder','folder_1', 'reapit'],axis = 1)\n",
    "Extracted_PID = Extracted_PID.rename({'IVS': 'Ivs', 'LVPW': 'Lvpw','LVIDd':'Lvidd','LVIDs':'Lvids',\n",
    "                                     'LVEDV':'Lvedv','LVESV':'Lvesv','DT':'Dt','IVRT':'Ivrt',\n",
    "                                     'mitral_e':'E','mitral_a':'A'}, axis=1)\n",
    "Extracted_PID['Ef'] = (Extracted_PID['Lvedv'] - Extracted_PID['Lvesv'])/Extracted_PID['Lvedv']*100\n",
    "\n",
    "#removing the rows that have null values in ExamDate/EF\n",
    "print(\"Total Rows before null removal is \", len(Extracted_PID), \" and Total Patients is \",len(Extracted_PID['PatientID'].unique()))\n",
    "Extracted_PID = Extracted_PID[Extracted_PID['ExamDate'].notna()]\n",
    "#Extracted_PID = Extracted_PID[Extracted_PID['Ef'].notna()]\n",
    "Extracted_PID = Extracted_PID.sort_values(by=['PatientID','ExamDate']).reset_index(drop=True)\n",
    "print(\"Total Rows after null removal is \", len(Extracted_PID), \" and Total Patients is \",len(Extracted_PID['PatientID'].unique()))\n",
    "print(\"\\nTotal rows that have null in each columns is\\n\", Extracted_PID.isnull().sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "whole-fantasy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows is  27726  and Total Patients is  14527\n",
      "\n",
      "Total rows that have null in each columns is\n",
      " PatientID            0\n",
      "ExamDate             0\n",
      "Ao               19172\n",
      "Av               19172\n",
      "La               19172\n",
      "Rv               19172\n",
      "Efslope          19172\n",
      "Ivs               3853\n",
      "Lvpw              3859\n",
      "Epss             19172\n",
      "Lvidd             3856\n",
      "Lvids             3856\n",
      "Lvedv             5093\n",
      "Lvesv             5086\n",
      "Ef                5094\n",
      "Hr               19172\n",
      "Co               19172\n",
      "Dt                4219\n",
      "Ivrt              4420\n",
      "E                 4107\n",
      "A                 4017\n",
      "TDI_e_lateral    17513\n",
      "TDI_e_septal     20644\n",
      "TDI_s_lateral    21120\n",
      "TDI_s_septal     21127\n",
      "LA_MAX_VOLUME    24457\n",
      "LA_MIN_VOLUME    24449\n",
      "TR_VELOCITY      23284\n",
      "dtype: int64\n",
      "Total Rows is  27726  and Total Patients is  14527\n"
     ]
    }
   ],
   "source": [
    "#concatenating the ref,pef with charlies data\n",
    "Mackay_raw = pd.concat([masterData,Extracted_PID],sort=False).drop_duplicates().reset_index(drop=True)\n",
    "print(\"Total Rows is \", len(Mackay_raw), \" and Total Patients is \",len(Mackay_raw['PatientID'].unique()))\n",
    "Mackay_raw = Mackay_raw.sort_values(by=['PatientID','ExamDate']).reset_index(drop=True)\n",
    "print(\"\\nTotal rows that have null in each columns is\\n\", Mackay_raw.isnull().sum(axis = 0))\n",
    "Mackay_raw = Mackay_raw[Mackay_raw['ExamDate'].notna()]\n",
    "#removing the rows that have negative values in EF as it might be invalid\n",
    "#Mackay_raw = Mackay_raw.loc[Mackay_raw['Ef']>0].reset_index(drop=True)\n",
    "print(\"Total Rows is \", len(Mackay_raw), \" and Total Patients is \",len(Mackay_raw['PatientID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mackay_raw.sort_values(by=['ExamDate']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "objective-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the Video Data\n",
    "extension = \".json\"\n",
    "null_id = []\n",
    "video_id = []\n",
    "heart_rate = []\n",
    "BSA = []\n",
    "age = []\n",
    "gender = []\n",
    "MackayData = Mackay_raw.copy(deep=True)\n",
    "\n",
    "for i in range(len(MackayData)):\n",
    "    PID = MackayData['PatientID'][i]\n",
    "    date = str(MackayData['ExamDate'][i].date())          \n",
    "    data_path = os.path.join('data/A4C',str(PID))\n",
    "    try:\n",
    "        files = os.listdir(data_path)\n",
    "        max_prob = 0\n",
    "        for f in files:\n",
    "            if(extension in f):\n",
    "                json_path = os.path.join(data_path,f)\n",
    "                with open(json_path) as f:\n",
    "                    json_info = json.load(f)\n",
    "                    if(json_info['study']['ed']==date):\n",
    "                        if(max_prob<json_info['classification']['prob']):\n",
    "                            max_prob = json_info['classification']['prob']\n",
    "                            max_prob_id = json_info['id']\n",
    "                            json_date = json_info['study']['ed']\n",
    "                            json_heart_rate = json_info['tags']['HeartRate']\n",
    "                            json_BSA = json_info['study']['BSA']\n",
    "                            try:\n",
    "                                json_gender = json_info['tags']['PatientSex']\n",
    "                            except KeyError:\n",
    "                                json_gender = json_info['study']['gender']\n",
    "                            json_age = json_info['study']['age']\n",
    "        if(json_date!=date):\n",
    "            raise FileNotFoundError\n",
    "        video_id.append(max_prob_id)\n",
    "        heart_rate.append(json_heart_rate)\n",
    "        age.append(json_age)\n",
    "        BSA.append(json_BSA)\n",
    "        if(json_gender=='M' or json_gender=='O'):\n",
    "            gender.append(\"Male\")\n",
    "        elif (json_gender=='F' or json_gender=='1'):\n",
    "            gender.append(\"Female\")\n",
    "        else:\n",
    "            gender.append(np.nan)\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        video_id.append(np.nan)\n",
    "        heart_rate.append(np.nan)\n",
    "        null_id.append(MackayData['PatientID'][i])\n",
    "        BSA.append(np.nan)\n",
    "        age.append(np.nan)\n",
    "        gender.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "latin-deviation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rows that have null in each columns is\n",
      " PatientID            0\n",
      "ExamDate             0\n",
      "Ao               19172\n",
      "Av               19172\n",
      "La               19172\n",
      "Rv               19172\n",
      "Efslope          19172\n",
      "Ivs               3853\n",
      "Lvpw              3859\n",
      "Epss             19172\n",
      "Lvidd             3856\n",
      "Lvids             3856\n",
      "Lvedv             5093\n",
      "Lvesv             5086\n",
      "Ef                5094\n",
      "Hr                6296\n",
      "Co               19172\n",
      "Dt                4219\n",
      "Ivrt              4420\n",
      "E                 4107\n",
      "A                 4017\n",
      "TDI_e_lateral    17513\n",
      "TDI_e_septal     20644\n",
      "TDI_s_lateral    21120\n",
      "TDI_s_septal     21127\n",
      "LA_MAX_VOLUME    24457\n",
      "LA_MIN_VOLUME    24449\n",
      "TR_VELOCITY      23284\n",
      "age               8429\n",
      "A4C_video_id      6296\n",
      "gender            6453\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "MackayData['age'] = age\n",
    "MackayData['A4C_video_id'] = video_id\n",
    "MackayData['Hr'] = heart_rate\n",
    "MackayData['gender'] = gender\n",
    "print(\"\\nTotal rows that have null in each columns is\\n\", MackayData.isnull().sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "radical-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the Video Data\n",
    "extension = \".json\"\n",
    "null_id = []\n",
    "video_id = []\n",
    "heart_rate = []\n",
    "BSA = []\n",
    "age = []\n",
    "gender = []\n",
    "MackayData = MackayData.copy(deep=True)\n",
    "root = \"data/PLAX/data/PLAX/\"\n",
    "frames = 16\n",
    "for i in range(len(MackayData)):\n",
    "    PID = MackayData['PatientID'][i]\n",
    "    date = str(MackayData['ExamDate'][i].date())          \n",
    "    data_path = os.path.join(root,str(PID))\n",
    "    max_prob_id = np.nan\n",
    "    json_heart_rate = np.nan\n",
    "    json_age = np.nan\n",
    "    json_BSA = np.nan\n",
    "    json_gender = np.nan\n",
    "    try:\n",
    "        files = os.listdir(data_path)\n",
    "        max_prob = 0\n",
    "        for f in files:\n",
    "            if(extension in f):\n",
    "                json_path = os.path.join(data_path,f)\n",
    "                with open(json_path) as f:\n",
    "                    json_info = json.load(f)\n",
    "                    if(json_info['study']['ed']==date and json_info['n_frames']>=16):\n",
    "                        if(max_prob<json_info['prob']):\n",
    "                            max_prob = json_info['prob']\n",
    "                            max_prob_id = json_info['id']\n",
    "                            json_date = json_info['study']['ed']\n",
    "                            json_heart_rate = json_info['tags']['HeartRate']\n",
    "                            json_BSA = json_info['study']['BSA']\n",
    "                            try:\n",
    "                                json_gender = json_info['tags']['PatientSex']\n",
    "                            except KeyError:\n",
    "                                json_gender = json_info['study']['gender']\n",
    "                            json_age = json_info['study']['age']\n",
    "        if(json_date!=date):\n",
    "            raise FileNotFoundError\n",
    "        video_id.append(max_prob_id)\n",
    "        heart_rate.append(json_heart_rate)\n",
    "        age.append(json_age)\n",
    "        BSA.append(json_BSA)\n",
    "        if(json_gender=='M' or json_gender=='O'):\n",
    "            gender.append(\"Male\")\n",
    "        elif (json_gender=='F' or json_gender=='1'):\n",
    "            gender.append(\"Female\")\n",
    "        else:\n",
    "            gender.append(np.nan)\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        video_id.append(np.nan)\n",
    "        heart_rate.append(np.nan)\n",
    "        null_id.append(MackayData['PatientID'][i])\n",
    "        BSA.append(np.nan)\n",
    "        age.append(np.nan)\n",
    "        gender.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "surrounded-person",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rows that have null in each columns is\n",
      " PatientID            0\n",
      "ExamDate             0\n",
      "Ao               19172\n",
      "Av               19172\n",
      "La               19172\n",
      "Rv               19172\n",
      "Efslope          19172\n",
      "Ivs               3853\n",
      "Lvpw              3859\n",
      "Epss             19172\n",
      "Lvidd             3856\n",
      "Lvids             3856\n",
      "Lvedv             5093\n",
      "Lvesv             5086\n",
      "Ef                5094\n",
      "Hr                6296\n",
      "Co               19172\n",
      "Dt                4219\n",
      "Ivrt              4420\n",
      "E                 4107\n",
      "A                 4017\n",
      "TDI_e_lateral    17513\n",
      "TDI_e_septal     20644\n",
      "TDI_s_lateral    21120\n",
      "TDI_s_septal     21127\n",
      "LA_MAX_VOLUME    24457\n",
      "LA_MIN_VOLUME    24449\n",
      "TR_VELOCITY      23284\n",
      "age               8429\n",
      "A4C_video_id      6296\n",
      "gender            6453\n",
      "PLAX_video_id    11812\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "MackayData['PLAX_video_id'] = video_id\n",
    "print(\"\\nTotal rows that have null in each columns is\\n\", MackayData.isnull().sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "precious-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_date = {}\n",
    "for pid in list(MackayData['PatientID'].unique()):\n",
    "    last_date[pid] = MackayData.loc[MackayData['PatientID']==pid].tail(1)['ExamDate'].iloc[0]\n",
    "days_alive = []\n",
    "for i in range(len(MackayData)):\n",
    "    days_alive.append((last_date[MackayData[\"PatientID\"][i]] - MackayData['ExamDate'][i]).days)\n",
    "MackayData[\"days_alive\"] = days_alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "alike-danish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27726 14527\n"
     ]
    }
   ],
   "source": [
    "MackayData.to_csv('Generated_csv_files/Mackay_all_data_Mortality.csv')\n",
    "print(len(MackayData) , len(MackayData['PatientID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mechanical-cylinder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15914\n",
      "\n",
      "Total rows that have null in each columns is\n",
      " PatientID            0\n",
      "ExamDate             0\n",
      "Ao                9436\n",
      "Av                9436\n",
      "La                9436\n",
      "Rv                9436\n",
      "Efslope           9436\n",
      "Ivs               2155\n",
      "Lvpw              2156\n",
      "Epss              9436\n",
      "Lvidd             2158\n",
      "Lvids             2158\n",
      "Lvedv             2334\n",
      "Lvesv             2333\n",
      "Ef                2334\n",
      "Hr                1585\n",
      "Co                9436\n",
      "Dt                2331\n",
      "Ivrt              2430\n",
      "E                 2262\n",
      "A                 2234\n",
      "TDI_e_lateral    10229\n",
      "TDI_e_septal     11649\n",
      "TDI_s_lateral    11933\n",
      "TDI_s_septal     11934\n",
      "LA_MAX_VOLUME    13151\n",
      "LA_MIN_VOLUME    13147\n",
      "TR_VELOCITY      13006\n",
      "age               2900\n",
      "A4C_video_id      1585\n",
      "gender            1681\n",
      "PLAX_video_id        0\n",
      "days_alive           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Mackay_no_null = MackayData.loc[MackayData['PLAX_video_id'].notnull()].reset_index(drop=True)\n",
    "Mackay_no_null = Mackay_no_null.sort_values(by=['PatientID', 'ExamDate']).reset_index(drop=True)\n",
    "print(len(Mackay_no_null))\n",
    "Mackay_no_null = Mackay_no_null.drop_duplicates(subset = ['PatientID', 'ExamDate'],keep = 'last').reset_index(drop = True)\n",
    "print(\"\\nTotal rows that have null in each columns is\\n\", Mackay_no_null.isnull().sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "temporal-genetics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14717, 10010)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Mackay_no_null) , len(Mackay_no_null['PatientID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "operational-colony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13083\n",
      "4207\n",
      "\n",
      "Total rows that dont have null in each columns is\n",
      " PatientID         4207\n",
      "Mortality_Date    4207\n",
      "CV_death          1675\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Mackay_Mortality_dates = pd.read_csv('Mortality_HF_mackay.csv')\n",
    "Mackay_Mortality_dates['Patient_ID'] = Mackay_Mortality_dates['Patient_ID'].astype(str)\n",
    "Mackay_Mortality_dates = Mackay_Mortality_dates.rename(columns={'Patient_ID':'PatientID'})\n",
    "Mackay_Mortality_dates['Mortality_Date'] = pd.to_datetime(Mackay_Mortality_dates['Mortality_Date'],dayfirst=True)\n",
    "print(len(Mackay_Mortality_dates))\n",
    "Mackay_Mortality_dates = Mackay_Mortality_dates.dropna(subset=['Mortality_Date'])\n",
    "print(len(Mackay_Mortality_dates))\n",
    "merged_Frame = pd.merge(Mackay_Mortality_dates, Mackay_no_null, on = \"PatientID\", how='right')\n",
    "merged_Frame = merged_Frame.sort_values(by=['PatientID','ExamDate']).reset_index(drop=True)\n",
    "print(\"\\nTotal rows that dont have null in each columns is\\n\",Mackay_Mortality_dates.notnull().sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "armed-wiring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14717, 10010)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_Frame) , len(merged_Frame['PatientID'].unique())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "polar-pakistan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14717\n"
     ]
    }
   ],
   "source": [
    "#final_data = merged_Frame.groupby(['PatientID']).tail(2)\n",
    "final_data = merged_Frame\n",
    "final_data = final_data.sort_values(by=['PatientID','ExamDate']).reset_index(drop=True)\n",
    "death_days = []\n",
    "for i in range(len(final_data)):\n",
    "    death_days.append((pd.to_datetime(final_data.iloc[i]['Mortality_Date'])  - pd.to_datetime(final_data.iloc[i]['ExamDate'])).days)\n",
    "final_data['death_days'] = death_days\n",
    "print(len(final_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "military-denial",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(final_data)):\n",
    "    if(not final_data.iloc[i].isnull()['death_days']):\n",
    "        \n",
    "        #sanity checking\n",
    "        if(final_data['death_days'][i] < final_data['days_alive'][i]):\n",
    "            print(final_data['death_days'][i],final_data['days_alive'][i])\n",
    "            \n",
    "        final_data.at[i,'days_alive'] = final_data['death_days'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acquired-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get only those patients that have visits greater than 1 or if they have a mortality date\n",
    "final_data = final_data.loc[(final_data['days_alive']>=0) | (final_data['Mortality_Date'].notnull()) ].reset_index(drop=True)\n",
    "final_data = final_data.sort_values(by=['PatientID','ExamDate']).reset_index(drop=True)\n",
    "#final_data = final_data.drop_duplicates(subset=['PatientID'],keep='last')\n",
    "final_data = final_data.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "appointed-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "PID = list(final_data['PatientID'].unique())\n",
    "visits = {}\n",
    "for pid in PID:\n",
    "    visits[pid] = len(final_data.loc[final_data['PatientID']==pid])\n",
    "\n",
    "rows_done = visits.copy()\n",
    "final_data = final_data.sort_values(by=['PatientID','ExamDate']).reset_index(drop=True)\n",
    "#to get the duration in days between each visit\n",
    "n = len(final_data)\n",
    "i = 0\n",
    "visit_PID = []\n",
    "zero_ID = []\n",
    "while(i!=n):\n",
    "    Total_visits = visits[final_data['PatientID'][i]]\n",
    "    if(Total_visits==1):\n",
    "        visit_PID.append(0)\n",
    "        visits[final_data['PatientID'][i]] -=1\n",
    "        i +=1\n",
    "    else:\n",
    "        visit_diff = (final_data['ExamDate'][i+1] - final_data['ExamDate'][i]).days\n",
    "        visit_PID.append(visit_diff)\n",
    "        visits[final_data['PatientID'][i]] -=1\n",
    "        i +=1\n",
    "        \n",
    "#Sanity check \n",
    "n = 0\n",
    "visits_data_PID = []\n",
    "for key,value in rows_done.items():\n",
    "    n += value\n",
    "    if(visit_PID[n-1]!=0):\n",
    "        print(key,\"This key dosent have the correct visit\")\n",
    "\n",
    "    #to make a column that contains the total visits in the masterdata\n",
    "    for i in range(value):\n",
    "        visits_data_PID.append(value)\n",
    "        \n",
    "final_data[\"visit_duration\"] = visit_PID\n",
    "final_data[\"visits\"] = visits_data_PID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "thermal-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"data/PLAX/data/PLAX/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-christopher",
   "metadata": {},
   "source": [
    "<b> Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "interesting-collector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the root data to PLAX is :  data/PLAX/data/PLAX/\n",
      "Total Patient Id's in video dataset 10899\n",
      "Total Patient Id's in ground truth Dataset :  14527\n",
      "Total Patient Id's in ground truth Dataset that only have a plax video :  10010\n",
      "Total Patient Id's in patients with mortality dataset :  4207\n",
      "total Patient Id's with  a survial date or if they have a mortality :  10010\n",
      "Total matching patients between patients with all cause mortality and the ground truth dataset ID's that have a PLAX view :  1068 / 10010\n",
      "Total matching patients between patients with all cause mortality and the ground truth dataset ID's that have a PLAX view and taking only the valid ID's that have a survial date:  1068 / 10010\n"
     ]
    }
   ],
   "source": [
    "print(\"the root data to PLAX is : \", root)\n",
    "plax_video_id = set(os.listdir(root))\n",
    "print(\"Total Patient Id's in video dataset\", len(plax_video_id))\n",
    "mackay_GT_id = set(MackayData['PatientID'].values)\n",
    "print\n",
    "print(\"Total Patient Id's in ground truth Dataset : \", len(mackay_GT_id))\n",
    "mackay_GT_no_null_PLAX_id = set(Mackay_no_null['PatientID'].values)\n",
    "print(\"Total Patient Id's in ground truth Dataset that only have a plax video : \", len(mackay_GT_no_null_PLAX_id))\n",
    "Mackay_Mortality_id = set(Mackay_Mortality_dates['PatientID'].values)\n",
    "print(\"Total Patient Id's in patients with mortality dataset : \", len(Mackay_Mortality_id))\n",
    "final_data_id = set(final_data['PatientID'].values)\n",
    "print(\"total Patient Id's with  a survial date or if they have a mortality : \", len(final_data_id))\n",
    "print(\"Total matching patients between patients with all cause mortality and the ground truth dataset ID's that have a PLAX view : \" ,len(mackay_GT_no_null_PLAX_id.intersection(Mackay_Mortality_id)),\"/\", len(mackay_GT_no_null_PLAX_id))\n",
    "print(\"Total matching patients between patients with all cause mortality and the ground truth dataset ID's that have a PLAX view and taking only the valid ID's that have a survial date: \" ,len(final_data_id.intersection(Mackay_Mortality_id)),\"/\", len(final_data_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "intelligent-burton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14717, 10010)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_data), len( set(final_data['PatientID'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "international-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m = final_data.loc[~((final_data['days_alive']<=0) & (final_data['death_days'].isnull()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cathedral-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m = final_data.loc[~((final_data['days_alive']<=0) & (final_data['death_days'].isnull()))]\n",
    "data_m = data_m.sort_values(by=['PatientID','ExamDate']).reset_index(drop=True)\n",
    "data_m = data_m.drop_duplicates(subset='PatientID', keep=\"first\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "heated-inclusion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6821, 3925)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_m),len( set(data_m['PatientID'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "optional-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv('Generated_csv_files/Mackay_mortality_all_PLAX.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dressed-hypothetical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of visits 6083\n",
      "Total Patients who are dead within 365 days 589\n",
      "Total Patients who are alive within 365 days 5494\n",
      "539 589\n",
      "3160 5494\n",
      "6083 3626\n",
      "After correction and removing the mortality patients in the alive set\n",
      "539 539\n",
      "3087 5355\n"
     ]
    }
   ],
   "source": [
    "time_to_take = 365\n",
    "final_data_df = final_data.loc[((final_data['days_alive']>=time_to_take)) |((final_data['death_days']<=time_to_take))].reset_index(drop=True)\n",
    "mortality = []\n",
    "for i in range(len(final_data_df)):\n",
    "    if (final_data_df['days_alive'][i]>=time_to_take):\n",
    "        mortality.append(0)\n",
    "    elif (final_data_df['death_days'][i]<=time_to_take):\n",
    "        mortality.append(1)\n",
    "final_data_df['mortality'] = mortality\n",
    "final_data_df = final_data_df.sort_values(by=['PatientID','ExamDate']).reset_index(drop=True)\n",
    "print(\"total number of visits\", len(final_data_df))\n",
    "print(\"Total Patients who are dead within \" + str(time_to_take) + \" days\", len(final_data_df.loc[final_data_df['mortality']==1]))\n",
    "print(\"Total Patients who are alive within \" + str(time_to_take) + \" days\", len(final_data_df.loc[final_data_df['mortality']==0]))\n",
    "print(len(final_data_df.loc[final_data_df['mortality']==1]['PatientID'].unique()) , len(final_data_df.loc[final_data_df['mortality']==1]))\n",
    "print(len(final_data_df.loc[final_data_df['mortality']==0]['PatientID'].unique()) , len(final_data_df.loc[final_data_df['mortality']==0]))\n",
    "print(len(final_data_df),len(final_data_df['PatientID'].unique()))\n",
    "death_pid = list(final_data_df.loc[final_data_df['mortality']==1]['PatientID'].unique())\n",
    "data_death_pid  = final_data_df[final_data_df['PatientID'].isin(death_pid)]\n",
    "data_death_pid = data_death_pid.drop_duplicates(subset='PatientID', keep=\"last\").reset_index()\n",
    "final_data_df = final_data_df[~final_data_df['PatientID'].isin(death_pid)]\n",
    "frames = [final_data_df, data_death_pid]\n",
    "result = pd.concat(frames,sort=False)\n",
    "print(\"After correction and removing the mortality patients in the alive set\")\n",
    "print(len(result.loc[result['mortality']==1]['PatientID'].unique()) , len(result.loc[result['mortality']==1]))\n",
    "print(len(result.loc[result['mortality']==0]['PatientID'].unique()) , len(result.loc[result['mortality']==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ahead-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('Generated_csv_files/Mackay_mortality_within_' + str(time_to_take) + '_days.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-comparative",
   "metadata": {},
   "source": [
    "# Getting the Ejection Fraction values from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "proprietary-scout",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27726"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(MackayData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acknowledged-harassment",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mackay_raw = MackayData.sort_values(by=['PatientID','ExamDate']).reset_index(drop=True)\n",
    "PID = list(Mackay_raw['PatientID'].unique())\n",
    "visits = {}\n",
    "for pid in PID:\n",
    "    visits[pid] = len(Mackay_raw.loc[Mackay_raw['PatientID']==pid])\n",
    "\n",
    "rows_done = visits.copy()\n",
    "final_data = Mackay_raw.sort_values(by=['PatientID','ExamDate']).reset_index(drop=True)\n",
    "#to get the duration in days between each visit\n",
    "n = len(Mackay_raw)\n",
    "i = 0\n",
    "visit_PID = []\n",
    "zero_ID = []\n",
    "while(i!=n):\n",
    "    Total_visits = visits[Mackay_raw['PatientID'][i]]\n",
    "    if(Total_visits==1):\n",
    "        visit_PID.append(0)\n",
    "        visits[Mackay_raw['PatientID'][i]] -=1\n",
    "        i +=1\n",
    "    else:\n",
    "        visit_diff = (Mackay_raw['ExamDate'][i+1] - Mackay_raw['ExamDate'][i]).days\n",
    "        visit_PID.append(visit_diff)\n",
    "        visits[Mackay_raw['PatientID'][i]] -=1\n",
    "        i +=1\n",
    "        \n",
    "#Sanity check \n",
    "n = 0\n",
    "visits_data_PID = []\n",
    "for key,value in rows_done.items():\n",
    "    n += value\n",
    "    if(visit_PID[n-1]!=0):\n",
    "        print(key,\"This key dosent have the correct visit\")\n",
    "\n",
    "    #to make a column that contains the total visits in the masterdata\n",
    "    for i in range(value):\n",
    "        visits_data_PID.append(value)\n",
    "        \n",
    "Mackay_raw[\"visit_duration\"] = visit_PID\n",
    "Mackay_raw[\"visits\"] = visits_data_PID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "exempt-spoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in baseline 4759\n",
      "Total number of rows in 365 days Event_Name is  4759\n",
      "\n",
      "Total rows that have null in each columns is\n",
      " PatientID            0\n",
      "ExamDate             0\n",
      "Ao                8078\n",
      "Av                8078\n",
      "La                8078\n",
      "Rv                8078\n",
      "Efslope           8078\n",
      "Ivs               1355\n",
      "Lvpw              1351\n",
      "Epss              8078\n",
      "Lvidd             1350\n",
      "Lvids             1350\n",
      "Lvedv             1645\n",
      "Lvesv             1644\n",
      "Ef                1645\n",
      "Hr                2445\n",
      "Co                8078\n",
      "Dt                1587\n",
      "Ivrt              1697\n",
      "E                 1539\n",
      "A                 1431\n",
      "TDI_e_lateral     5678\n",
      "TDI_e_septal      7138\n",
      "TDI_s_lateral     7374\n",
      "TDI_s_septal      7378\n",
      "LA_MAX_VOLUME     8915\n",
      "LA_MIN_VOLUME     8915\n",
      "TR_VELOCITY       8627\n",
      "age               3420\n",
      "A4C_video_id      2445\n",
      "gender            2502\n",
      "PLAX_video_id     4601\n",
      "days_alive           0\n",
      "visit_duration       0\n",
      "Event_Name           0\n",
      "visit_ID             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Mackay_raw = Mackay_raw.loc[Mackay_raw['visits']>1]        \n",
    "Mackay_raw = Mackay_raw.sort_values(by=['PatientID','ExamDate']).reset_index(drop=True)\n",
    "time_to_visit = 365\n",
    "PID_visit_ID = []\n",
    "Mackay_2_visits = pd.DataFrame(columns = Mackay_raw.columns)\n",
    "visit_type = []\n",
    "for i in range(len(Mackay_raw)):\n",
    "    if(Mackay_raw[\"visit_duration\"][i]<=540 and Mackay_raw[\"visit_duration\"][i]>=180):\n",
    "        Mackay_2_visits = Mackay_2_visits.append(Mackay_raw.iloc[i])\n",
    "        Mackay_2_visits = Mackay_2_visits.append(Mackay_raw.iloc[i+1])\n",
    "        \n",
    "        visit_type.append(\"Baseline\")\n",
    "        visit_type.append(\"EventDay\")\n",
    "        \n",
    "        #to make a visit_ID token to keep track of each visit to make baselinea and 12-24 month visits rows\n",
    "        visit_ID = randrange(100000000000)\n",
    "        PID_visit_ID.append(visit_ID)\n",
    "        PID_visit_ID.append(visit_ID)\n",
    "Mackay_2_visits[\"Event_Name\"] = visit_type\n",
    "Mackay_2_visits[\"visit_ID\"] = PID_visit_ID\n",
    "Mackay_2_visits = Mackay_2_visits.drop_duplicates().reset_index(drop=True)\n",
    "Mackay_2_visits = Mackay_2_visits.sort_values(by=['PatientID','ExamDate']).reset_index(drop=True)\n",
    "print(\"Total number of rows in baseline\" , len(Mackay_2_visits.loc[Mackay_2_visits['Event_Name']=='Baseline']))\n",
    "print(\"Total number of rows in \" + str(time_to_take) + \" days Event_Name is \" , len(Mackay_2_visits.loc[Mackay_2_visits['Event_Name']=='EventDay']))\n",
    "Mackay_2_visits = Mackay_2_visits.drop(['visits'], axis = 1)\n",
    "print(\"\\nTotal rows that have null in each columns is\\n\", Mackay_2_visits.isnull().sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "caring-broadcasting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9518"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Mackay_2_visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "proprietary-bankruptcy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlapping PID's is 4522\n",
      "matching PID's is 3011\n",
      "PID's that dont have a study at the event day 559\n",
      "PID's that dont have a baseline 952\n",
      "PID's that dont have a study after event day is or baseline removed due to null is  1511\n",
      "\n",
      " overlapping PID's is 3011\n",
      "matching PID's is 3011\n",
      "PID's that dont have a study at the event day 0\n",
      "PID's that dont have a baseline 0\n",
      "\n",
      "Total rows that have null in each columns is\n",
      " PatientID            0\n",
      "ExamDate             0\n",
      "Ao                5045\n",
      "Av                5045\n",
      "La                5045\n",
      "Rv                5045\n",
      "Efslope           5045\n",
      "Ivs                  3\n",
      "Lvpw                 0\n",
      "Epss              5045\n",
      "Lvidd                0\n",
      "Lvids                0\n",
      "Lvedv                0\n",
      "Lvesv                0\n",
      "Ef                   0\n",
      "Hr                1308\n",
      "Co                5045\n",
      "Dt                 220\n",
      "Ivrt               312\n",
      "E                  180\n",
      "A                   54\n",
      "TDI_e_lateral     3099\n",
      "TDI_e_septal      4180\n",
      "TDI_s_lateral     4363\n",
      "TDI_s_septal      4367\n",
      "LA_MAX_VOLUME     5455\n",
      "LA_MIN_VOLUME     5455\n",
      "TR_VELOCITY       5461\n",
      "age               1915\n",
      "A4C_video_id      1308\n",
      "gender            1343\n",
      "PLAX_video_id     2865\n",
      "days_alive           0\n",
      "visit_duration       0\n",
      "Event_Name           0\n",
      "visit_ID             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#removing the rows have null values in video or negative values in EF\n",
    "Mackay_no_null_ef = Mackay_2_visits.loc[Mackay_2_visits['Ef'] > 0].reset_index(drop=True)\n",
    "\n",
    "baseline_no_null = Mackay_no_null_ef.loc[Mackay_no_null_ef['Event_Name']=='Baseline'].reset_index(drop=True)\n",
    "after_event_no_null = Mackay_no_null_ef.loc[Mackay_no_null_ef['Event_Name']=='EventDay'].reset_index(drop=True)\n",
    "\n",
    "#due to the removal of some rows ,some patient ID's have only visit instead of 2 ,hence they all need to be removed\n",
    "baseline_PID = set(baseline_no_null['visit_ID'].unique())\n",
    "after_event_PID = set(after_event_no_null['visit_ID'].unique())\n",
    "print(\"overlapping PID's is\", len(baseline_PID.union(after_event_PID)))\n",
    "print(\"matching PID's is\", len(baseline_PID.intersection(after_event_PID)))\n",
    "print(\"PID's that dont have a study at the event day\", len(baseline_PID - after_event_PID))\n",
    "print(\"PID's that dont have a baseline\", len(after_event_PID - baseline_PID))\n",
    "\n",
    "total_PID_no_study = list(baseline_PID - after_event_PID) + list(after_event_PID - baseline_PID)\n",
    "print(\"PID's that dont have a study after event day is or baseline removed due to null is \", len(total_PID_no_study))\n",
    "\n",
    "Mackay_no_null_ef = Mackay_no_null_ef.sort_values(by=['PatientID','ExamDate']).reset_index(drop=True)\n",
    "df_with_event = pd.DataFrame()\n",
    "for i in range(len(Mackay_no_null_ef)):\n",
    "    if(not (Mackay_no_null_ef['visit_ID'][i] in total_PID_no_study)):\n",
    "        df_with_event = df_with_event.append(Mackay_no_null_ef[i:i+1])\n",
    "        \n",
    "df_with_event = df_with_event.reset_index(drop=True)\n",
    "\n",
    "masterdata = df_with_event\n",
    "masterdata = masterdata.sort_values(by=['PatientID','ExamDate']).reset_index(drop=True)\n",
    "baseline = masterdata.loc[masterdata['Event_Name']=='Baseline'].reset_index(drop=True)\n",
    "after_event_months = masterdata.loc[masterdata['Event_Name']=='EventDay'].reset_index(drop=True)\n",
    "\n",
    "#sanity check\n",
    "baseline_PID = set(baseline['visit_ID'].unique())\n",
    "after_event_PID = set(after_event_months['visit_ID'].unique())\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n overlapping PID's is\", len(baseline_PID.union(after_event_PID)))\n",
    "print(\"matching PID's is\", len(baseline_PID.intersection(after_event_PID)))\n",
    "print(\"PID's that dont have a study at the event day\", len(baseline_PID - after_event_PID))\n",
    "print(\"PID's that dont have a baseline\", len(after_event_PID - baseline_PID))\n",
    "print(\"\\nTotal rows that have null in each columns is\\n\", masterdata.isnull().sum(axis = 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "criminal-concord",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total class 0 is 1003\n",
      "total class 1 is 987\n",
      "total class 2 is 1021\n",
      "train set should contain 2408.8\n",
      "test set should contain 602.2\n"
     ]
    }
   ],
   "source": [
    "DataFrame = get_train_val_dataset(masterdata)\n",
    "DataFrame.to_csv('Generated_csv_files/Mackay_EF_within_' + str(time_to_visit) + '_days_with_' + str(time_to_take) + '_mortality.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "intermediate-reader",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_dead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "periodic-withdrawal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_alive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-surrey",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e751d02d6254c91a5337ccacd3da0a06bef2f97f2b707c83ebd4c7968b8ad4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
